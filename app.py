# -*- coding: utf-8 -*-
"""newapp.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D_SVhXGpyUoqqhRs_SFWQQpD5Qd5CDrK
"""
import streamlit as st
import pandas as pd
from datetime import datetime 
import os
import requests 
from PIL import Image  # For resizing images
from io import BytesIO, StringIO  # For handling file-like objects

# Import pipeline functions (ensure they are implemented in `pipeline.py`)
from pipeline import (
    bertrend_analysis,
    calculate_trend_momentum,
    visualize_trends,
    generate_investigative_report,
    categorize_momentum
)

# Configure page
st.set_page_config(
    page_title="Election Threat Monitor",
    page_icon="üåç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Session state initialization
if 'processed' not in st.session_state:
    st.session_state.processed = False
if 'clustered_df' not in st.session_state:
    st.session_state.clustered_df = pd.DataFrame()  # Empty DataFrame as default
if 'momentum_states' not in st.session_state:
    st.session_state.momentum_states = {}
if 'emerging_trends' not in st.session_state:
    st.session_state.emerging_trends = []
if 'reports' not in st.session_state:
    st.session_state.reports = {}

# Main app
def main():
    st.set_page_config(page_title="BERTrend Analysis Dashboard", layout="wide")
    st.title("üá¨üá¶ Gabon Election Threat Intelligence Dashboard")
    st.markdown("### Real-time Narrative Monitoring & FIMI Detection")

    # User choice: Real-time analysis or preprocessed data
    analysis_option = st.radio(
        "Choose an option:",
        ["üìä Analyze Raw Data (Real-Time)", "üìà View Preprocessed Data Results"],
        help="Select whether you want to analyze raw data or view results from preprocessed data."
    )

    if analysis_option == "üìä Analyze Raw Data (Real-Time)":
        # File upload for raw data
        uploaded_file = st.file_uploader(
            "Upload Social Media Data (CSV/Excel)",
            type=["csv", "xlsx"],
            help="Requires columns: 'text', 'Timestamp', 'URL', 'Source', 'Platform'"
        )

        if uploaded_file:
            @st.cache_data
            def load_data(file):
                try:
                    # Detect file extension and encoding
                    if file.name.endswith('.csv'):
                        try:
                            df = pd.read_csv(file, encoding='utf-16', sep='\t', low_memory=False)
                        except UnicodeError:
                            file.seek(0)  # Reset file pointer
                            df = pd.read_csv(file, encoding='utf-8', low_memory=False)
                    else:
                        df = pd.read_excel(file)
                    df['Timestamp'] = pd.to_datetime(df['Timestamp'])
                    return df
                except Exception as e:
                    st.error(f"‚ùå Failed to parse CSV data: {str(e)}")
                    return pd.DataFrame()

            df = load_data(uploaded_file)
            if df.empty:
                st.error("‚ùå Failed to load data. Please check your file.")
                return

            if st.button("üöÄ Analyze Data", help="Run full BERTrend analysis", type="primary"):
                with st.status("Processing data...", expanded=True) as status:
                    try:
                        st.write("üîç Running temporal-semantic clustering...")
                        clustered_df = bertrend_analysis(df)
                        status.update(label="Temporal-semantic clustering complete!", state="running")

                        st.write("üìà Calculating narrative momentum...")
                        emerging_trends, momentum_states = calculate_trend_momentum(clustered_df)
                        status.update(label="Narrative momentum calculation complete!", state="running")

                        st.write("üé® Generating visualizations...")
                        viz_path = visualize_trends(clustered_df, momentum_states)
                        status.update(label="Visualizations generated!", state="complete")

                        st.session_state.processed = True
                        st.session_state.clustered_df = clustered_df
                        st.session_state.momentum_states = momentum_states
                        st.session_state.emerging_trends = emerging_trends
                        st.session_state.viz_path = viz_path
                        st.rerun()
                    except Exception as e:
                        st.error(f"‚ùå An error occurred during analysis: {e}")
                        status.update(label="Analysis failed!", state="error")
                        st.stop()

        else:
            st.info("Using default dataset...")
            df = load_default_dataset()
            if df.empty:
                st.error("‚ùå Failed to load default dataset.")
                return

            if st.button("üöÄ Analyze Default Data", help="Run full BERTrend analysis", type="primary"):
                with st.status("Processing data...", expanded=True) as status:
                    try:
                        st.write("üîç Running temporal-semantic clustering...")
                        clustered_df = bertrend_analysis(df)
                        status.update(label="Temporal-semantic clustering complete!", state="running")

                        st.write("üìà Calculating narrative momentum...")
                        emerging_trends, momentum_states = calculate_trend_momentum(clustered_df)
                        status.update(label="Narrative momentum calculation complete!", state="running")

                        st.write("üé® Generating visualizations...")
                        viz_path = visualize_trends(clustered_df, momentum_states)
                        status.update(label="Visualizations generated!", state="complete")

                        st.session_state.processed = True
                        st.session_state.clustered_df = clustered_df
                        st.session_state.momentum_states = momentum_states
                        st.session_state.emerging_trends = emerging_trends
                        st.session_state.viz_path = viz_path
                        st.rerun()
                    except Exception as e:
                        st.error(f"‚ùå An error occurred during analysis: {e}")
                        status.update(label="Analysis failed!", state="error")
                        st.stop()

    elif analysis_option == "üìà View Preprocessed Data Results":
        upload_option = st.radio(
            "Choose an upload method:",
            ["Upload Locally", "Fetch from Google Drive"]
        )

        if upload_option == "Upload Locally":
            uploaded_file = st.file_uploader(
                "Upload Preprocessed Report (CSV)",
                type=["csv"],
                help="Requires columns: 'Cluster ID', 'First Detected', 'Last Updated', 'Momentum Score', 'Unique Sources', 'Report Summary', 'All URLs', 'Thread Categorization'"
            )
            if uploaded_file:
                try:
                    # Read CSV with UTF-8 encoding
                    df = pd.read_csv(uploaded_file, encoding='utf-8')

                    # Rename 'Cluster ID' to 'Cluster' to match visualization logic
                    df = df.rename(columns={'Cluster ID': 'Cluster'})

                    # Validate required columns
                    required_columns = {
                        'Cluster', 'First Detected', 'Last Updated', 'Momentum Score',
                        'Unique Sources', 'Report Summary', 'All URLs', 'Thread Categorization'
                    }
                    missing_cols = required_columns - set(df.columns)
                    if missing_cols:
                        st.error(f"‚ùå Missing required columns: {missing_cols}")
                        return

                    st.success("‚úÖ Preprocessed report loaded successfully!")
                    display_results(df)

                except Exception as e:
                    st.error(f"‚ùå Error reading CSV: {str(e)}")

        elif upload_option == "Fetch from Google Drive":
            # Input project and country names
            project_name = st.text_input("Enter Project Name", help="Example: GIZ")
            country_name = st.text_input("Enter Country Name", help="Example: Gabon")

            if project_name and country_name:
                main_folder_id = "1ASJ8S5eZempAj596lMrjdw2Uzmj7p_a7"

                # Fetch project folders
                project_folders = fetch_files_from_drive(main_folder_id)
                project_folder = next((folder for folder in project_folders if folder['name'] == project_name), None)
                if not project_folder:
                    st.error(f"‚ùå No folder found for project: {project_name}.")
                    return

                # Fetch country folders
                country_folders = fetch_files_from_drive(project_folder['id'])
                country_folder = next((folder for folder in country_folders if folder['name'] == country_name), None)
                if not country_folder:
                    st.error(f"‚ùå No folder found for country: {country_name} in project: {project_name}.")
                    return

                # Fetch CSV files
                csv_files = [file for file in fetch_files_from_drive(country_folder['id']) if file['mimeType'] == 'text/csv']
                if not csv_files:
                    st.error(f"‚ùå No CSV files found in the folder for {country_name} in project: {project_name}.")
                    return

                csv_file_names = [file['name'] for file in csv_files]
                selected_csv_file = st.selectbox("Select a CSV file to load", csv_file_names)
                selected_csv_file_id = next((file['id'] for file in csv_files if file['name'] == selected_csv_file), None)

                if not selected_csv_file_id:
                    st.error(f"‚ùå Could not find file ID for: {selected_csv_file}.")
                    return

                if st.button("Load Selected CSV File"):
                    with st.spinner("Downloading and loading the selected CSV file..."):
                        df = download_csv_from_drive(selected_csv_file_id)
                        if df.empty:
                            st.error("‚ùå Failed to load data from Google Drive.")
                            return

                        df = df.rename(columns={'Cluster ID': 'Cluster'})
                        display_results(df)

    # Display results if processed
    if hasattr(st.session_state, 'processed') and st.session_state.processed:
        clustered_df = st.session_state.clustered_df
        momentum_states = st.session_state.momentum_states
        emerging_trends = st.session_state.emerging_trends
        viz_path = st.session_state.viz_path

        tab1, tab2, tab3 = st.tabs(["üìä Cluster Analytics", "üìú Threat Reports", "üö® Threat Categorization"])

        with tab1:
            if viz_path:
                st.image(viz_path, caption="Narrative Growth vs Momentum Intensity", use_column_width='always')
            if 'Cluster' in clustered_df.columns:
                bar_data = clustered_df.groupby('Cluster')[['Total Posts', 'Peak Activity']].sum().reset_index()
                st.bar_chart(bar_data.set_index('Cluster'))

        with tab2:
            if 'Cluster' in clustered_df.columns:
                cluster_selector = st.selectbox("Select Cluster for Detailed Analysis", options=clustered_df['Cluster'].unique())
                cluster_data = clustered_df[clustered_df['Cluster'] == cluster_selector]
                st.markdown(f"#### Report Summary for Cluster {cluster_selector}")
                st.info(cluster_data['Report Summary'].iloc[0])
                st.markdown("### Associated URLs")
                urls = cluster_data['All URLs'].iloc[0].split('\n')
                for url in urls:
                    st.markdown(f"- [{url.strip()}]({url.strip()})")

        with tab3:
            if 'Thread Categorization' in clustered_df.columns and 'Cluster' in clustered_df.columns:
                categorization_df = clustered_df[['Cluster', 'Thread Categorization']]
                st.dataframe(categorization_df)

            st.download_button(
                label="üì• Download Full Report",
                data=clustered_df.to_csv(index=False).encode('utf-8'),
                file_name=f"threat_report_{datetime.now().date()}.csv",
                mime="text/csv"
            )

if __name__ == "__main__":
    main()
