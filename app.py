# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qg2WWNjPE9tZdHKALAhcfU6Z60E9PXQQ
"""

import streamlit as st
import pandas as pd
import time
import matplotlib.pyplot as plt
import seaborn as sns

# Replace with your GitHub username, repository name, and CSV file name
GITHUB_USERNAME = "hanna-tes"
GITHUB_REPO = "Radar-System"
CSV_FILENAME = "Radar_Gabon.csv"  # Replace with your CSV file name
GITHUB_CSV_URL = f"https://raw.githubusercontent.com/{GITHUB_USERNAME}/{GITHUB_REPO}/main/{CSV_FILENAME}"

def load_data():
    try:
        df = pd.read_csv(GITHUB_CSV_URL)
        return df
    except Exception as e:
        st.error(f"Error loading CSV from GitHub: {e}")
        return None

def process_data(df):
    time.sleep(2)  # Simulate data processing
    st.write("Running temporal-semantic clustering...")
    time.sleep(3)  # Simulate clustering
    return df  # Return the processed DataFrame (replace with your logic)

def admin_page():
    st.title("Admin Page: Upload Data")
    uploaded_file = st.file_uploader("Upload Social Media Data (CSV)", type=["csv"])

    if uploaded_file is not None:
        file_details = {"FileName": uploaded_file.name, "FileType": uploaded_file.type, "FileSize": uploaded_file.size}
        st.write(file_details)

        if st.button("Analyze Data"):
            with st.spinner("Processing data..."):
                df = pd.read_csv(uploaded_file)
                processed_df = process_data(df)
                if processed_df is not None:
                    st.success("Data analysis complete!")
                    # Replace with your logic to update the GitHub CSV file or store the processed data
                    # For simplicity, we are just displaying it here.
                    st.write(processed_df)
                else:
                    st.error("Data analysis failed.")

def user_page():
    st.title("Gabon Election Threat Intelligence Dashboard")
    st.subheader("Real-time Narrative Monitoring & FIMI Detection")

    df = load_data()

    if df is not None:
        tab1, tab2 = st.tabs(["Cluster Summaries", "Visualizations"])

        with tab1:
            cluster_ids = sorted(df['Cluster ID'].unique())
            selected_cluster = st.selectbox("Select Cluster ID", cluster_ids)
            cluster_data = df[df['Cluster ID'] == selected_cluster]

            st.write(f"**Cluster ID:** {selected_cluster}")
            for index, row in cluster_data.iterrows():
                st.write(f"**First Detected:** {row['First Detected']}")
                st.write(f"**Last Updated:** {row['Last Updated']}")

                col1, col2 = st.columns(2)
                col1.metric("Momentum Score", row['Momentum Score'])
                col2.metric("Unique Sources", row['Unique Sources'])

                st.write(f"**Report Summary:** {row['Report Summary']}")
                st.write(f"**Example Text 1:** {row['Example Text 1']}")
                st.link_button("Example URL 1", row['Example URL 1'])
                # ... (add other fields)

        with tab2:
            st.subheader("Cluster Statistics")
            # Example visualization: Momentum Score distribution
            plt.figure(figsize=(8, 6))
            sns.histplot(df['Momentum Score'], kde=True)
            st.pyplot(plt)

            # Add more visualizations as needed

def main():
    if st.session_state.get("admin_mode", False):
        admin_page()
    else:
        user_page()

    if st.sidebar.checkbox("Admin Mode"):
        st.session_state.admin_mode = True
    else:
        st.session_state.admin_mode = False

if __name__ == "__main__":
    main()