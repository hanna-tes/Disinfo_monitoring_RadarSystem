# -*- coding: utf-8 -*-
"""newapp.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D_SVhXGpyUoqqhRs_SFWQQpD5Qd5CDrK
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import os

# Import your existing functions (make sure to remove notebook-specific code)
from pipeline import (
        bertrend_analysis,
        calculate_trend_momentum,
        visualize_trends,
        generate_investigative_report,
        categorize_momentum
    )

# Configure page
st.set_page_config(
    page_title="Election Threat Monitor",
    page_icon="ðŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Session state initialization
if 'processed' not in st.session_state:
    st.session_state.processed = False
if 'reports' not in st.session_state:
    st.session_state.reports = {}
#checking the existance
if os.path.exists("pipeline.py"):
    print("âœ… pipeline.py found!")
else:
    print("âŒ pipeline.py is missing!")

print("Current Directory:", os.getcwd())
print("Files and Folders:", os.listdir("."))

#removes running loop error
import asyncio

try:
    asyncio.get_running_loop()
except RuntimeError:
    asyncio.set_event_loop(asyncio.new_event_loop())

# Main app
def main():
    st.title("ðŸ‡¬ðŸ‡¦ Gabon Election Threat Intelligence Dashboard")
    st.markdown("### Real-time Narrative Monitoring & FIMI Detection")

    # File upload
    uploaded_file = st.file_uploader(
        "Upload Social Media Data (CSV/Excel)",
        type=["csv", "xlsx"],
        help="Requires columns: 'text', 'Timestamp', 'URL', 'Source'"
    )

    if uploaded_file:
        # Load and preprocess data
        @st.cache_data
        def load_data(file):
            if file.name.endswith('.csv'):
                df = pd.read_csv(file)
            else:
                df = pd.read_excel(file)
            df['Timestamp'] = pd.to_datetime(df['Timestamp'])
            return df

        df = load_data(uploaded_file)

        # Analysis trigger
        if st.button("ðŸš€ Analyze Data", help="Run full BERTrend analysis"):
            with st.status("Processing data...", expanded=True) as status:
                st.write("ðŸ” Running temporal-semantic clustering...")
                clustered_df = bertrend_analysis(df)

                st.write("ðŸ“ˆ Calculating narrative momentum...")
                emerging_trends, momentum_states = calculate_trend_momentum(clustered_df)

                st.write("ðŸŽ¨ Generating visualizations...")
                viz_path = visualize_trends(clustered_df, momentum_states)
                
                            if clustered_df is None:
                st.write("clustered_df is None!")
            elif clustered_df.empty:
                st.write("clustered_df is empty!")
            else:
                st.write("Inspecting clustered_df before visualize_trends:")
                st.write(clustered_df)
                st.write(f"clustered_df shape: {clustered_df.shape}")
                st.write(f"clustered_df is empty: {clustered_df.empty}")
                st.write(f"Number of -1 clusters: {(clustered_df['Cluster'] == -1).sum()}")
                st.write(f"Unique Cluster values: {clustered_df['Cluster'].unique()}")
            
            st.write("Clustered Dataframe being passed to visualization function")
            st.write(clustered_df)
            st.write("Momentum States being passed to visualization function")
            st.write(momentum_states)

                

                status.update(label="Analysis complete!", state="complete", expanded=False)

            st.session_state.processed = True
            st.session_state.clustered_df = clustered_df
            st.session_state.momentum_states = momentum_states
            st.session_state.emerging_trends = emerging_trends
            st.rerun()

    # Display results
    if st.session_state.processed:
        clustered_df = st.session_state.clustered_df
        momentum_states = st.session_state.momentum_states
        emerging_trends = st.session_state.emerging_trends
        

        # Create tabs
        tab1, tab2, tab3 = st.tabs([
            "ðŸ“Š Cluster Analytics",
            "ðŸ“œ Threat Reports",
            "ðŸš¨ Threat Categorization"
        ])

        with tab1:
            col1, col2 = st.columns([2, 1])
            with col1:
                visualize_trends(clustered_df, momentum_states)

            with col2:
                st.markdown("### Top Clusters by Momentum")
                momentum_df = pd.DataFrame([
                    {
                        "Cluster": cluster,
                        "Momentum": score,
                        "Sources": len(momentum_states[cluster]['sources']),
                        "Last Active": momentum_states[cluster]['last_update'].strftime('%Y-%m-%d %H:%M')
                    }
                    for cluster, score in emerging_trends
                ])
                st.dataframe(
                    momentum_df.sort_values('Momentum', ascending=False),
                    column_config={
                        "Momentum": st.column_config.ProgressColumn(
                            format="%.0f",
                            min_value=0,
                            max_value=momentum_df['Momentum'].max()
                        )
                    },
                    height=400
                )

        with tab2:
            cluster_selector = st.selectbox(
                "Select Cluster for Detailed Analysis",
                [cluster for cluster, _ in emerging_trends],
                format_func=lambda x: f"Cluster {x}"
            )

            cluster_score = next((score for cluster, score in emerging_trends if cluster == cluster_selector), 0)

            category = categorize_momentum(cluster_score)
            color_map = {
             'Tier 1: Ambient Noise (Normal baseline activity)': 'ðŸŸ¢',
             'Tier 2: Emerging Narrative (Potential story development)': 'ðŸŸ¡',
             'Tier 3: Coordinated Activity (Organized group behavior)': 'ðŸŸ ',
             'Tier 4: Viral Emergency (Requires immediate response)': 'ðŸ”´'
              }
            #color = color_map.get(category.split(':')[0], 'âšª')
            color = color_map.get(category, 'âšª')
            st.markdown(f"""
             **Threat Classification:** {color} `{category}`
              """)
            if cluster_selector not in st.session_state.reports:
                with st.spinner("Generating intelligence report..."): 
                    # Get the cluster score from emerging_trends
                    cluster_score = next((score for cluster, score in emerging_trends if cluster == cluster_selector), 0)
                    cluster_data = clustered_df[clustered_df['Cluster'] == cluster_selector]
                    cluster_data['momentum_score'] = cluster_score  # Critical line added here
                    report = generate_investigative_report(
                        cluster_data,
                        momentum_states,
                        cluster_selector
                    )
                    st.session_state.reports[cluster_selector] = report

            report = st.session_state.reports[cluster_selector]

            with st.expander("ðŸ“„ Full Intelligence Report", expanded=True):
                st.markdown(f"#### Cluster {cluster_selector} Analysis")
                st.markdown(report['report'])

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("### Example Content")
                for i, text in enumerate(report['sample_texts'][:5]):
                    st.markdown(f"**Document {i+1}**")
                    st.info(text[:500] + "..." if len(text) > 500 else text)

            with col2:
                st.markdown("### Associated URLs")
                for url in report['sample_urls']:
                    st.markdown(f"- [{url[:50]}...]({url})")

        with tab3:
            st.markdown("### Threat Tier Classification")
            intel_df = pd.DataFrame([{
                "Cluster": cluster,
                "Momentum": score
                #"Category": categorize_momentum(score)
            } for cluster, score in emerging_trends])

            st.bar_chart(
                intel_df.set_index('Cluster')['Momentum'],
                color="#FF4B4B",
                height=400
            )

            st.dataframe(
                intel_df,
                #column_config={
                #    "Category": st.column_config.SelectboxColumn(
                 #       help="Threat classification tiers"
                 #   )
                #},
                hide_index=True
            )

        # Download button
        st.sidebar.download_button(
            label="ðŸ“¥ Download Full Report",
            data=convert_df(intel_df),
            file_name=f"threat_report_{datetime.now().date()}.csv",
            mime="text/csv"
        )

def convert_df(df):
    return df.to_csv(index=False).encode('utf-8')

if __name__ == "__main__":
    main()
