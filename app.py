# -*- coding: utf-8 -*-
"""newapp.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D_SVhXGpyUoqqhRs_SFWQQpD5Qd5CDrK
"""
import streamlit as st
import pandas as pd
from datetime import datetime 
import os
import requests 
from PIL import Image  # For resizing images
from io import BytesIO, StringIO  # For handling file-like objects

# Import pipeline functions (ensure they are implemented in `pipeline.py`)
from pipeline import (
    bertrend_analysis,
    calculate_trend_momentum,
    visualize_trends,
    generate_investigative_report,
    categorize_momentum
)

# Configure page
st.set_page_config(
    page_title="Election Threat Monitor",
    page_icon="üåç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# GitHub raw CSV URL for default dataset
DEFAULT_DATASET_URL = "https://raw.githubusercontent.com/hanna-tes/RadarSystem/refs/heads/main/Gabon_intelligence_reportMarch.csv"

def load_default_dataset():
    """Load default preprocessed dataset from GitHub"""
    try:
        response = requests.get(DEFAULT_DATASET_URL)
        if response.status_code == 200:
            df = pd.read_csv(BytesIO(response.content))
            
            # Validate required columns
            expected_columns = {
                'Cluster ID',
                'First Detected',
                'Last Updated',
                'Momentum Score',
                'Total Posts',
                'Peak Activity',
                'Unique Sources',
                'Report Summary',
                'All URLs',
                'Thread Categorization'
            }
            
            missing_cols = expected_columns - set(df.columns)
            if missing_cols:
                st.error(f"‚ùå Default dataset missing required columns: {missing_cols}")
                return pd.DataFrame()
                
            # Convert timestamps
            df['First Detected'] = pd.to_datetime(df['First Detected'], errors='coerce')
            df['Last Updated'] = pd.to_datetime(df['Last Updated'], errors='coerce')
            
            return df
        else:
            st.error(f"‚ùå Failed to fetch default dataset. Status code: {response.status_code}")
            return pd.DataFrame()
    except Exception as e:
        st.error(f"‚ùå Error loading default dataset: {str(e)}")
        return pd.DataFrame()

def display_results(df):
    expected_columns = {
        'Cluster ID',
        'First Detected',
        'Last Updated',
        'Momentum Score',
        'Total Posts',
        'Peak Activity',
        'Unique Sources',
        'Report Summary',
        'All URLs',
        'Thread Categorization'
    }

    if not expected_columns.issubset(df.columns):
        missing_columns = expected_columns - set(df.columns)
        st.error(f"‚ùå Missing required columns: {missing_columns}. Found: {list(df.columns)}")
        return

    tab1, tab2, tab3 = st.tabs([
        "üìä Cluster Analytics",
        "üìú Threat Reports",
        "üö® Threat Categorization"
    ])

    with tab1:
        st.markdown("### Cluster Overview")
        st.dataframe(df)

        # Fallback image visualization
        heatmap_url = "https://raw.githubusercontent.com/hanna-tes/RadarSystem/main/trend_visualization_March_AP.png"
        try:
            response = requests.get(heatmap_url)
            if response.status_code == 200:
                img = Image.open(BytesIO(response.content))
                resized_img = img.resize((800, 600))
                st.image(resized_img, caption="Narrative Growth vs Momentum Intensity", use_container_width='always')
            else:
                st.warning("‚ö†Ô∏è Heatmap unavailable ‚Äî using fallback visualization")
                st.line_chart(df.set_index('Cluster ID')['Momentum Score'])
        except Exception as e:
            st.warning("‚ö†Ô∏è Heatmap unavailable ‚Äî using fallback visualization")
            st.line_chart(df.set_index('Cluster ID')['Momentum Score'])

        st.markdown("### Total Posts and Peak Activity by Cluster")
        bar_data = df.groupby('Cluster ID')[['Total Posts', 'Peak Activity']].sum().reset_index()
        st.bar_chart(bar_data.set_index('Cluster ID'))

    with tab2:
        cluster_selector = st.selectbox(
            "Select Cluster for Detailed Analysis",
            options=df['Cluster ID'].unique(),
            format_func=lambda x: f"Cluster {x}"
        )
        cluster_data = df[df['Cluster ID'] == cluster_selector]
        st.markdown(f"#### Report Summary for Cluster {cluster_selector}")
        st.info(cluster_data['Report Summary'].iloc[0] if not cluster_data.empty else "No summary available")

    with tab3:
        categorization_df = df[['Cluster ID', 'Thread Categorization']]
        st.dataframe(categorization_df)

        st.download_button(
            label="üì• Download Full Report",
            data=df.to_csv(index=False).encode('utf-8'),
            file_name=f"threat_report_{datetime.now().date()}.csv",
            mime="text/csv"
        )

def fetch_files_from_drive(folder_id):
    """Mock function for Google Drive file listing"""
    return [
        {"id": "mock_csv_id_123", "name": "Gabon_intelligence_report_3.csv", "mimeType": "text/csv"}
    ]

def download_csv_from_drive(file_id):
    """Mock function for downloading CSV from Google Drive"""
    return pd.read_csv("Gabon_intelligence_report_3.csv")

def main():
    st.title("üá¨üá¶ Gabon Election Threat Intelligence Dashboard")
    st.markdown("### Real-time Narrative Monitoring & FIMI Detection")

    analysis_option = st.radio(
        "Choose an option:",
        ["üìä Analyze Raw Data (Real-Time)", "üìà View Preprocessed Data Results"],
        help="Select whether you want to analyze raw data or view results from preprocessed data."
    )

    if analysis_option == "üìä Analyze Raw Data (Real-Time)":
        uploaded_file = st.file_uploader(
            "Upload Social Media Data (CSV/Excel)",
            type=["csv", "xlsx"],
            help="Requires columns: 'text', 'Timestamp', 'URL', 'Source'"
        )

        if uploaded_file:
            @st.cache_data
            def load_data(file):
                try:
                    if file.name.endswith('.csv'):
                        try:
                            df = pd.read_csv(file, encoding='utf-16', sep='\t', low_memory=False)
                        except UnicodeError:
                            file.seek(0)
                            df = pd.read_csv(file, encoding='utf-8', low_memory=False)
                    else:
                        df = pd.read_excel(file)
                    df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')
                    return df
                except Exception as e:
                    st.error(f"‚ùå Error reading file: {str(e)}")
                    return pd.DataFrame()

            df = load_data(uploaded_file)
            if not df.empty:
                st.success("‚úÖ Raw data loaded successfully!")
                # Simulate clustering
                df['Cluster ID'] = df['Cluster'] = 0
                st.session_state.processed = True
                st.session_state.clustered_df = df
                st.rerun()

        else:
            st.info("Using default dataset...")
            df = load_default_dataset()
            if df.empty:
                st.error("‚ùå Failed to load default dataset from GitHub")
                return
            st.success("‚úÖ Default dataset loaded successfully!")
            st.dataframe(df.head())

    elif analysis_option == "üìà View Preprocessed Data Results":
        upload_option = st.radio(
            "Choose an upload method:",
            ["Upload Locally", "Fetch from Google Drive", "Use Default Dataset"]
        )

        if upload_option == "Upload Locally":
            uploaded_file = st.file_uploader(
                "Upload Preprocessed Report (CSV)",
                type=["csv"],
                help="Requires columns: 'Cluster ID', 'First Detected', 'Last Updated', 'Momentum Score', 'Unique Sources', 'Report Summary', 'All URLs', 'Thread Categorization'"
            )
            if uploaded_file:
                try:
                    df = pd.read_csv(uploaded_file, encoding='utf-8')
                    st.success("‚úÖ Preprocessed report loaded successfully!")
                    display_results(df)
                except Exception as e:
                    st.error(f"‚ùå Error reading CSV: {str(e)}")

        elif upload_option == "Fetch from Google Drive":
            project_name = st.text_input("Enter Project Name", help="Example: GIZ")
            country_name = st.text_input("Enter Country Name", help="Example: Gabon")

            if project_name and country_name:
                main_folder_id = "1ASJ8S5eZempAj596lMrjdw2Uzmj7p_a7"

                project_folders = fetch_files_from_drive(main_folder_id)
                project_folder = next((f for f in project_folders if f['name'] == project_name), None)

                if not project_folder:
                    st.error(f"‚ùå No folder found for project: {project_name}.")
                    return

                country_folders = fetch_files_from_drive(project_folder['id'])
                country_folder = next((f for f in country_folders if f['name'] == country_name), None)

                if not country_folder:
                    st.error(f"‚ùå No folder found for country: {country_name} in project: {project_name}.")
                    return

                csv_files = [f for f in fetch_files_from_drive(country_folder['id']) if f['mimeType'] == 'text/csv']
                if not csv_files:
                    st.error(f"‚ùå No CSV files found in the folder for {country_name} in project: {project_name}.")
                    return

                selected_csv_file = st.selectbox(
                    "Select a CSV file to load",
                    [f['name'] for f in csv_files],
                    help="Choose a CSV file to view its contents."
                )

                selected_file_id = next((f['id'] for f in csv_files if f['name'] == selected_csv_file), None)
                if not selected_file_id:
                    st.error(f"‚ùå Could not find file ID for: {selected_csv_file}.")
                    return

                if st.button("Load Selected CSV File"):
                    with st.spinner("üì• Downloading and loading CSV from Google Drive..."):
                        df = download_csv_from_drive(selected_file_id)
                        if df.empty:
                            st.error("‚ùå Failed to load data from Google Drive.")
                        else:
                            st.success("‚úÖ CSV file loaded successfully!")
                            display_results(df)

        elif upload_option == "Use Default Dataset":
            with st.spinner("üì• Loading default preprocessed dataset from GitHub..."):
                df = load_default_dataset()
                if not df.empty:
                    st.success("‚úÖ Default dataset loaded successfully!")
                    display_results(df)
                else:
                    st.error("‚ùå Failed to load default dataset.")

if __name__ == "__main__":
    main()
